{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression,Ridge, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import importlib\n",
    "\n",
    "#add path to script\n",
    "sys.path.append(os.path.abspath(\"../src/data/\"))\n",
    "sys.path.append(os.path.abspath(\"../src/model/\"))\n",
    "sys.path.append(os.path.abspath(\"../src/plots_helper/\"))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Cleaning\n",
    "\n",
    "This first part of the notebook shows all the data cleaning steps. It has to be run once to obtain the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Movie Data\n",
    "\n",
    "For our analysis, we will need 2 movie datasets: CMU Movies Dataset & Kaggle Movies Dataset. \\\n",
    "\\\n",
    "<b>Why 2 datasets ?</b> \\\n",
    "\\\n",
    "For our purpose, we need movie data and corresponding movie plots (CMU movie metadata & CMU plot summaries respectively). We will then restrict the analysis to American movies, leaving us with approximately half of the original dataset — 20,788 movies. \\\n",
    "Since our aim is to assess the correlation of the data with historical events, the release date is really important. We want to have the precise date, not just the year. However, dropping all rows where the date is not precise will cause us to lose a lot of data, as only 13,335 movies have precise dates. This is where the Kaggle dataset comes in. When the date is not precise, we will try to match the movie with the corresponding from this dataset and extract its date. Using this method, we recover a lot of data and end up with 17,077 movies.\n",
    "\n",
    "<b>Data preprocessing steps</b> \\\n",
    "We will apply the following pipeline:\n",
    "\n",
    "<ul>\n",
    "    <li>load CMU, plots and Kaggle datasets </li>\n",
    "    <li>CMU data preprocessing</li><ul>\n",
    "        <li>Remove unnecessary columns</li>\n",
    "        <li>Check for NaN values in plots</li>\n",
    "        <li>Merge CMU metadata and plots on Wikipedia ID — take only movies present in both</li>\n",
    "        <li>Convert plots to lowercase</li>\n",
    "        <li>Put each column of the movie metadata in the wanted format. For example, {\"/m/09c7w0\": \"United States of America\"} should become \"United States of America\"</li>\n",
    "        <li>Keep only American movies</li>\n",
    "    </ul>\n",
    "    <li>Kaggle data preprocessing</li><ul>\n",
    "        <li>Remove unnecessary columns</li>\n",
    "        <li>Put each column of the movie metadata in the correct format. For example, {\"/m/09c7w0\": \"United States of America\"} should become \"United States of America\"</li>\n",
    "        <li>Keep only American movies</li>\n",
    "        <li>Drop NaN values and duplicated rows (if present)</li>\n",
    "    </ul>\n",
    "    <li>For incomplete or missing dates, merge with the Kaggle dataset using the movie title, and ultimately the date</li>\n",
    "    <li>Check for outliers (e.g., incorrect dates)</li>\n",
    "    <li>Save the cleaned dataset</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the DataLoader class\n",
    "from src.data.data_loading import DataLoader\n",
    "\n",
    "raw = 'data/RAW/'\n",
    "clean = 'data/CLEAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load CMU movie metadata\n",
      "\n",
      "\n",
      "load plot data\n",
      "\n",
      "\n",
      "load GVD data\n",
      "\n",
      "\n",
      "load kaggle movie data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loader (see data_loading.py for the code regarding this function)\n",
    "data_loader = DataLoader(raw,clean)\n",
    "# Load raw data\n",
    "CMU_movie_metadata, CMU_plot_summary, GVD_data, Kaggle_movies_metadata = data_loader.load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 0.1.1 CMU metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freebase movie ID</th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Box office revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196793</th>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28463795</th>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n",
       "      <td>{\"/m/05b4w\": \"Norway\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9363483</th>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/04306rv\": \"German Language\"}</td>\n",
       "      <td>{\"/m/0345h\": \"Germany\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35228177</th>\n",
       "      <td>/m/0j7hxnt</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34980460</th>\n",
       "      <td>/m/0g4pl34</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>2011-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...</td>\n",
       "      <td>{\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971909</th>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913762</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>{\"/m/03_9r\": \"Japanese Language\"}</td>\n",
       "      <td>{\"/m/03_3d\": \"Japan\"}</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476867</th>\n",
       "      <td>/m/02w7zz8</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/0d060g\": \"Canada\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81741 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Freebase movie ID  \\\n",
       "Wikipedia movie ID                     \n",
       "975900                     /m/03vyhn   \n",
       "3196793                    /m/08yl5d   \n",
       "28463795                  /m/0crgdbh   \n",
       "9363483                   /m/0285_cd   \n",
       "261236                     /m/01mrr1   \n",
       "...                              ...   \n",
       "35228177                  /m/0j7hxnt   \n",
       "34980460                  /m/0g4pl34   \n",
       "9971909                   /m/02pygw1   \n",
       "913762                     /m/03pcrp   \n",
       "12476867                  /m/02w7zz8   \n",
       "\n",
       "                                                           Movie name  \\\n",
       "Wikipedia movie ID                                                      \n",
       "975900                                                 Ghosts of Mars   \n",
       "3196793             Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "28463795                                                  Brun bitter   \n",
       "9363483                                              White Of The Eye   \n",
       "261236                                              A Woman in Flames   \n",
       "...                                                               ...   \n",
       "35228177                                     Mermaids: The Body Found   \n",
       "34980460                                                      Knuckle   \n",
       "9971909                                             Another Nice Mess   \n",
       "913762              The Super Dimension Fortress Macross II: Lover...   \n",
       "12476867                                                      Spliced   \n",
       "\n",
       "                   Release date  Box office revenue  Runtime  \\\n",
       "Wikipedia movie ID                                             \n",
       "975900               2001-08-24          14010832.0     98.0   \n",
       "3196793              2000-02-16                 NaN     95.0   \n",
       "28463795                   1988                 NaN     83.0   \n",
       "9363483                    1987                 NaN    110.0   \n",
       "261236                     1983                 NaN    106.0   \n",
       "...                         ...                 ...      ...   \n",
       "35228177             2011-03-19                 NaN    120.0   \n",
       "34980460             2011-01-21                 NaN     96.0   \n",
       "9971909              1972-09-22                 NaN     66.0   \n",
       "913762               1992-05-21                 NaN    150.0   \n",
       "12476867                   2002                 NaN     86.0   \n",
       "\n",
       "                                             Languages  \\\n",
       "Wikipedia movie ID                                       \n",
       "975900              {\"/m/02h40lc\": \"English Language\"}   \n",
       "3196793             {\"/m/02h40lc\": \"English Language\"}   \n",
       "28463795            {\"/m/05f_3\": \"Norwegian Language\"}   \n",
       "9363483             {\"/m/02h40lc\": \"English Language\"}   \n",
       "261236               {\"/m/04306rv\": \"German Language\"}   \n",
       "...                                                ...   \n",
       "35228177            {\"/m/02h40lc\": \"English Language\"}   \n",
       "34980460            {\"/m/02h40lc\": \"English Language\"}   \n",
       "9971909             {\"/m/02h40lc\": \"English Language\"}   \n",
       "913762               {\"/m/03_9r\": \"Japanese Language\"}   \n",
       "12476867            {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                                                            Countries  \\\n",
       "Wikipedia movie ID                                                      \n",
       "975900                      {\"/m/09c7w0\": \"United States of America\"}   \n",
       "3196793                     {\"/m/09c7w0\": \"United States of America\"}   \n",
       "28463795                                       {\"/m/05b4w\": \"Norway\"}   \n",
       "9363483                                {\"/m/07ssc\": \"United Kingdom\"}   \n",
       "261236                                        {\"/m/0345h\": \"Germany\"}   \n",
       "...                                                               ...   \n",
       "35228177                    {\"/m/09c7w0\": \"United States of America\"}   \n",
       "34980460            {\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...   \n",
       "9971909                     {\"/m/09c7w0\": \"United States of America\"}   \n",
       "913762                                          {\"/m/03_3d\": \"Japan\"}   \n",
       "12476867                                      {\"/m/0d060g\": \"Canada\"}   \n",
       "\n",
       "                                                               Genres  \n",
       "Wikipedia movie ID                                                     \n",
       "975900              {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "3196793             {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  \n",
       "28463795            {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  \n",
       "9363483             {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "261236                                        {\"/m/07s9rl0\": \"Drama\"}  \n",
       "...                                                               ...  \n",
       "35228177                                      {\"/m/07s9rl0\": \"Drama\"}  \n",
       "34980460            {\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...  \n",
       "9971909                  {\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}  \n",
       "913762              {\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...  \n",
       "12476867            {\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...  \n",
       "\n",
       "[81741 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the raw CMU metadata first\n",
    "CMU_movie_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23890098</th>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31186339</th>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20663735</th>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231378</th>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595909</th>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34808485</th>\n",
       "      <td>The story is about Reema , a young Muslim scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096473</th>\n",
       "      <td>In 1928 Hollywood, director Leo Andreyev  look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35102018</th>\n",
       "      <td>American Luthier focuses on Randy Parsons’ tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8628195</th>\n",
       "      <td>Abdur Rehman Khan , a middle-aged dry fruit se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040782</th>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42303 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Plot\n",
       "Wikipedia movie ID                                                   \n",
       "23890098            Shlykov, a hard-working taxi driver and Lyosha...\n",
       "31186339            The nation of Panem consists of a wealthy Capi...\n",
       "20663735            Poovalli Induchoodan  is sentenced for six yea...\n",
       "2231378             The Lemon Drop Kid , a New York City swindler,...\n",
       "595909              Seventh-day Adventist Church pastor Michael Ch...\n",
       "...                                                               ...\n",
       "34808485            The story is about Reema , a young Muslim scho...\n",
       "1096473             In 1928 Hollywood, director Leo Andreyev  look...\n",
       "35102018            American Luthier focuses on Randy Parsons’ tra...\n",
       "8628195             Abdur Rehman Khan , a middle-aged dry fruit se...\n",
       "6040782             1940 - Operation Dynamo has just taken place. ...\n",
       "\n",
       "[42303 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will also have a look at the raw CMU plot summaries\n",
    "CMU_plot_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns in metadata\n",
    "CMU_movie_metadata.drop(['Freebase movie ID', 'Runtime'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Plot]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NAN in the plots\n",
    "CMU_plot_summary[CMU_plot_summary[\"Plot\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets\n",
    "Movie_Data = CMU_movie_metadata.merge(CMU_plot_summary,left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case the plot_summaries\n",
    "Movie_Data['Plot'] = Movie_Data['Plot'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert genres, countries and languages in an understandable format\n",
    "def extract_data(text):\n",
    "    # Look for all names using a regex pattern: it matches quoted text appearing after colon\n",
    "    return ', '.join(re.findall(r'\": \"([^\"]+)\"', text))\n",
    "\n",
    "for name in ['Genres','Countries','Languages'] :\n",
    "    Movie_Data[name] = Movie_Data[name].apply(extract_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Countries\n",
       "United States of America                                        17774\n",
       "India                                                            4628\n",
       "                                                                 3312\n",
       "United Kingdom                                                   2284\n",
       "Japan                                                            1157\n",
       "                                                                ...  \n",
       "France, Austria, Iraq, Iran                                         1\n",
       "United States of America, Serbia, Germany                           1\n",
       "South Africa, Ireland, United Kingdom                               1\n",
       "France, Australia, United Kingdom, Germany                          1\n",
       "Yugoslavia, Socialist Federal Republic of Yugoslavia, Serbia        1\n",
       "Name: count, Length: 1501, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for where our movies come from\n",
    "Movie_Data[\"Countries\"].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the countries: we conclude that the majority of CMU movies comes from the US. Hence, we will restrict our analysis to the real world violence in the US, to then correlate it to the movies produced in this country in a relative period of time. Our plan is to investigate both the influence in movie violence on real world crimes and the influence of major violents events in history on \"on screen\" violence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only American movies\n",
    "Movie_Data = Movie_Data[Movie_Data['Countries'].str.contains(\"United States of America\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20788, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the shape before any drop for dates\n",
    "Movie_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all movies where the date format is incomplete\n",
    "Movie_Data_date_wrong = Movie_Data[~Movie_Data['Release date'].str.match(r'^\\d{4}-\\d{2}-\\d{2}$', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13335"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of remaining datapoints if we drop all rows where the date format is incomplete\n",
    "Movie_Data.shape[0]-Movie_Data_date_wrong.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uhm, not that many movies are left. Thus, let's turn to the Kaggle dataset to solve this issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 0.1.2 Kaggle metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45461</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...</td>\n",
       "      <td>http://www.imdb.com/title/tt6209470/</td>\n",
       "      <td>439050</td>\n",
       "      <td>tt6209470</td>\n",
       "      <td>fa</td>\n",
       "      <td>رگ خواب</td>\n",
       "      <td>Rising and falling between a man and woman.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{'iso_639_1': 'fa', 'name': 'فارسی'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Rising and falling between a man and woman</td>\n",
       "      <td>Subdue</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45462</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111109</td>\n",
       "      <td>tt2028550</td>\n",
       "      <td>tl</td>\n",
       "      <td>Siglo ng Pagluluwal</td>\n",
       "      <td>An artist struggles to finish his work while a...</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>[{'iso_639_1': 'tl', 'name': ''}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Century of Birthing</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45463</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67758</td>\n",
       "      <td>tt0303758</td>\n",
       "      <td>en</td>\n",
       "      <td>Betrayal</td>\n",
       "      <td>When one of her hits goes wrong, a professiona...</td>\n",
       "      <td>...</td>\n",
       "      <td>2003-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>A deadly game of wits.</td>\n",
       "      <td>Betrayal</td>\n",
       "      <td>False</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45464</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227506</td>\n",
       "      <td>tt0008536</td>\n",
       "      <td>en</td>\n",
       "      <td>Satana likuyushchiy</td>\n",
       "      <td>In a small town live two brothers, one a minis...</td>\n",
       "      <td>...</td>\n",
       "      <td>1917-10-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satan Triumphant</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45465</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461257</td>\n",
       "      <td>tt6980792</td>\n",
       "      <td>en</td>\n",
       "      <td>Queerama</td>\n",
       "      <td>50 years after decriminalisation of homosexual...</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queerama</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45466 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adult                              belongs_to_collection    budget  \\\n",
       "0      False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1      False                                                NaN  65000000   \n",
       "2      False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3      False                                                NaN  16000000   \n",
       "4      False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "...      ...                                                ...       ...   \n",
       "45461  False                                                NaN         0   \n",
       "45462  False                                                NaN         0   \n",
       "45463  False                                                NaN         0   \n",
       "45464  False                                                NaN         0   \n",
       "45465  False                                                NaN         0   \n",
       "\n",
       "                                                  genres  \\\n",
       "0      [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1      [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2      [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3      [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                         [{'id': 35, 'name': 'Comedy'}]   \n",
       "...                                                  ...   \n",
       "45461  [{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...   \n",
       "45462                      [{'id': 18, 'name': 'Drama'}]   \n",
       "45463  [{'id': 28, 'name': 'Action'}, {'id': 18, 'nam...   \n",
       "45464                                                 []   \n",
       "45465                                                 []   \n",
       "\n",
       "                                   homepage      id    imdb_id  \\\n",
       "0      http://toystory.disney.com/toy-story     862  tt0114709   \n",
       "1                                       NaN    8844  tt0113497   \n",
       "2                                       NaN   15602  tt0113228   \n",
       "3                                       NaN   31357  tt0114885   \n",
       "4                                       NaN   11862  tt0113041   \n",
       "...                                     ...     ...        ...   \n",
       "45461  http://www.imdb.com/title/tt6209470/  439050  tt6209470   \n",
       "45462                                   NaN  111109  tt2028550   \n",
       "45463                                   NaN   67758  tt0303758   \n",
       "45464                                   NaN  227506  tt0008536   \n",
       "45465                                   NaN  461257  tt6980792   \n",
       "\n",
       "      original_language               original_title  \\\n",
       "0                    en                    Toy Story   \n",
       "1                    en                      Jumanji   \n",
       "2                    en             Grumpier Old Men   \n",
       "3                    en            Waiting to Exhale   \n",
       "4                    en  Father of the Bride Part II   \n",
       "...                 ...                          ...   \n",
       "45461                fa                      رگ خواب   \n",
       "45462                tl          Siglo ng Pagluluwal   \n",
       "45463                en                     Betrayal   \n",
       "45464                en          Satana likuyushchiy   \n",
       "45465                en                     Queerama   \n",
       "\n",
       "                                                overview  ... release_date  \\\n",
       "0      Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1      When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2      A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3      Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4      Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "...                                                  ...  ...          ...   \n",
       "45461        Rising and falling between a man and woman.  ...          NaN   \n",
       "45462  An artist struggles to finish his work while a...  ...   2011-11-17   \n",
       "45463  When one of her hits goes wrong, a professiona...  ...   2003-08-01   \n",
       "45464  In a small town live two brothers, one a minis...  ...   1917-10-21   \n",
       "45465  50 years after decriminalisation of homosexual...  ...   2017-06-09   \n",
       "\n",
       "           revenue runtime                                   spoken_languages  \\\n",
       "0      373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1      262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2              0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3       81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4       76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "...            ...     ...                                                ...   \n",
       "45461          0.0    90.0             [{'iso_639_1': 'fa', 'name': 'فارسی'}]   \n",
       "45462          0.0   360.0                  [{'iso_639_1': 'tl', 'name': ''}]   \n",
       "45463          0.0    90.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "45464          0.0    87.0                                                 []   \n",
       "45465          0.0    75.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "         status                                            tagline  \\\n",
       "0      Released                                                NaN   \n",
       "1      Released          Roll the dice and unleash the excitement!   \n",
       "2      Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3      Released  Friends are the people who let you be yourself...   \n",
       "4      Released  Just When His World Is Back To Normal... He's ...   \n",
       "...         ...                                                ...   \n",
       "45461  Released         Rising and falling between a man and woman   \n",
       "45462  Released                                                NaN   \n",
       "45463  Released                             A deadly game of wits.   \n",
       "45464  Released                                                NaN   \n",
       "45465  Released                                                NaN   \n",
       "\n",
       "                             title  video vote_average vote_count  \n",
       "0                        Toy Story  False          7.7     5415.0  \n",
       "1                          Jumanji  False          6.9     2413.0  \n",
       "2                 Grumpier Old Men  False          6.5       92.0  \n",
       "3                Waiting to Exhale  False          6.1       34.0  \n",
       "4      Father of the Bride Part II  False          5.7      173.0  \n",
       "...                            ...    ...          ...        ...  \n",
       "45461                       Subdue  False          4.0        1.0  \n",
       "45462          Century of Birthing  False          9.0        3.0  \n",
       "45463                     Betrayal  False          3.8        6.0  \n",
       "45464             Satan Triumphant  False          0.0        0.0  \n",
       "45465                     Queerama  False          0.0        0.0  \n",
       "\n",
       "[45466 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the data\n",
    "Kaggle_movies_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the rows of interest\n",
    "Kaggle_movies_metadata = Kaggle_movies_metadata[[\"production_countries\",\"release_date\",\"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "production_countries\n",
       "[{'iso_3166_1': 'US', 'name': 'United States of America'}]                                                                                    17851\n",
       "[]                                                                                                                                             6282\n",
       "[{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]                                                                                               2238\n",
       "[{'iso_3166_1': 'FR', 'name': 'France'}]                                                                                                       1654\n",
       "[{'iso_3166_1': 'JP', 'name': 'Japan'}]                                                                                                        1356\n",
       "                                                                                                                                              ...  \n",
       "[{'iso_3166_1': 'CZ', 'name': 'Czech Republic'}, {'iso_3166_1': 'DE', 'name': 'Germany'}, {'iso_3166_1': 'FR', 'name': 'France'}]                 1\n",
       "[{'iso_3166_1': 'FR', 'name': 'France'}, {'iso_3166_1': 'US', 'name': 'United States of America'}, {'iso_3166_1': 'IL', 'name': 'Israel'}]        1\n",
       "[{'iso_3166_1': 'DZ', 'name': 'Algeria'}]                                                                                                         1\n",
       "[{'iso_3166_1': 'TR', 'name': 'Turkey'}, {'iso_3166_1': 'IT', 'name': 'Italy'}]                                                                   1\n",
       "[{'iso_3166_1': 'DK', 'name': 'Denmark'}, {'iso_3166_1': 'SE', 'name': 'Sweden'}, {'iso_3166_1': 'DE', 'name': 'Germany'}]                        1\n",
       "Name: count, Length: 2393, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check again the countries of production (spoiler: it's again the US)\n",
    "Kaggle_movies_metadata['production_countries'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract country of production for the Kaggle dataset\n",
    "def extract_country(text):\n",
    "    final_countries = \"\"\n",
    "    countries = ast.literal_eval(Kaggle_movies_metadata.production_countries[0])\n",
    "    for country in countries :\n",
    "        final_countries = final_countries + \" \" + country['name']\n",
    "    return final_countries \n",
    "\n",
    "Kaggle_movies_metadata.loc[:, 'production_countries'] = Kaggle_movies_metadata['production_countries'].apply(extract_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only American movies\n",
    "Kaggle_movies_metadata = Kaggle_movies_metadata[Kaggle_movies_metadata['production_countries'].str.contains(\"United States of America\", na=False)]\n",
    "Kaggle_movies_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45376, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NAN values\n",
    "Kaggle_movies_metadata.dropna(inplace=True)\n",
    "Kaggle_movies_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45376, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop full duplicates\n",
    "Kaggle_movies_metadata.drop_duplicates()\n",
    "Kaggle_movies_metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 0.1.3 Now that we have our two datasets, we can handle the date & duplicates problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Box office revenue</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7884497</th>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "      <td>1913-03-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Short Film, Science Fiction, Horror, Black-and...</td>\n",
       "      <td>dr. henry jekyll  sends a note to his fiancée,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7883633</th>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "      <td>1920-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silent film, English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Silent film, Horror, Indie, Science Fiction, B...</td>\n",
       "      <td>at the first transformation starts with jekyll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144774</th>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "      <td>1931-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Science Fiction, Horror, Black-and-white, Dram...</td>\n",
       "      <td>the film tells the story of dr. henry jekyll ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672796</th>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "      <td>1920-03-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silent film, English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Crime Fiction, Silent film, Horror, Science Fi...</td>\n",
       "      <td>henry jekyll  is a doctor of medicine, but he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490751</th>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "      <td>1941-08-12</td>\n",
       "      <td>1279000.0</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Science Fiction, Horror, Black-and-white</td>\n",
       "      <td>dr. jekyll  believes good and evil exist in ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870349</th>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "      <td>1908-03-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silent film</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Short Film, Silent film, Horror, Indie, Black-...</td>\n",
       "      <td>dr. jekyll and mr. hyde began with the raising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856323</th>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "      <td>1912-01-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Short Film, Horror, Black-and-white</td>\n",
       "      <td>james cruze's white-haired dr. jekyll has secr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Movie name Release date  Box office revenue  \\\n",
       "Wikipedia movie ID                                                             \n",
       "7884497             Dr. Jekyll and Mr. Hyde   1913-03-06                 NaN   \n",
       "7883633             Dr. Jekyll and Mr. Hyde      1920-04                 NaN   \n",
       "144774              Dr. Jekyll and Mr. Hyde   1931-12-31                 NaN   \n",
       "3672796             Dr. Jekyll and Mr. Hyde   1920-03-18                 NaN   \n",
       "2490751             Dr. Jekyll and Mr. Hyde   1941-08-12           1279000.0   \n",
       "7870349             Dr. Jekyll and Mr. Hyde   1908-03-07                 NaN   \n",
       "7856323             Dr. Jekyll and Mr. Hyde   1912-01-16                 NaN   \n",
       "\n",
       "                                        Languages                 Countries  \\\n",
       "Wikipedia movie ID                                                            \n",
       "7884497                          English Language  United States of America   \n",
       "7883633             Silent film, English Language  United States of America   \n",
       "144774                           English Language  United States of America   \n",
       "3672796             Silent film, English Language  United States of America   \n",
       "2490751                          English Language  United States of America   \n",
       "7870349                               Silent film  United States of America   \n",
       "7856323                          English Language  United States of America   \n",
       "\n",
       "                                                               Genres  \\\n",
       "Wikipedia movie ID                                                      \n",
       "7884497             Short Film, Science Fiction, Horror, Black-and...   \n",
       "7883633             Silent film, Horror, Indie, Science Fiction, B...   \n",
       "144774              Science Fiction, Horror, Black-and-white, Dram...   \n",
       "3672796             Crime Fiction, Silent film, Horror, Science Fi...   \n",
       "2490751                      Science Fiction, Horror, Black-and-white   \n",
       "7870349             Short Film, Silent film, Horror, Indie, Black-...   \n",
       "7856323                           Short Film, Horror, Black-and-white   \n",
       "\n",
       "                                                                 Plot  \n",
       "Wikipedia movie ID                                                     \n",
       "7884497             dr. henry jekyll  sends a note to his fiancée,...  \n",
       "7883633             at the first transformation starts with jekyll...  \n",
       "144774              the film tells the story of dr. henry jekyll ,...  \n",
       "3672796             henry jekyll  is a doctor of medicine, but he ...  \n",
       "2490751             dr. jekyll  believes good and evil exist in ev...  \n",
       "7870349             dr. jekyll and mr. hyde began with the raising...  \n",
       "7856323             james cruze's white-haired dr. jekyll has secr...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example\n",
    "Movie_Data[Movie_Data[\"Movie name\"] == \"Dr. Jekyll and Mr. Hyde\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7055</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>1941-08-12</td>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7823</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>1931-12-31</td>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8294</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>1920-03-18</td>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25134</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>2008-05-17</td>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            production_countries release_date                    title\n",
       "7055    United States of America   1941-08-12  Dr. Jekyll and Mr. Hyde\n",
       "7823    United States of America   1931-12-31  Dr. Jekyll and Mr. Hyde\n",
       "8294    United States of America   1920-03-18  Dr. Jekyll and Mr. Hyde\n",
       "25134   United States of America   2008-05-17  Dr. Jekyll and Mr. Hyde"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kaggle_movies_metadata[Kaggle_movies_metadata[\"title\"] == \"Dr. Jekyll and Mr. Hyde\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some names are similar in both datasets, but there is no duplicate. They are different movies. \\\n",
    "We will take that into account for the date algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iter on all rows of the wrong date dataset\n",
    "for index, row in Movie_Data_date_wrong.iterrows() :\n",
    "    # Is it in the Kaggle dataset ?\n",
    "    kaggle_data = Kaggle_movies_metadata[Kaggle_movies_metadata[\"title\"] == row[\"Movie name\"]]\n",
    "    \n",
    "    # If not, drop the row\n",
    "    if kaggle_data.empty :\n",
    "        #print(\"drop\")\n",
    "        Movie_Data.drop([index], inplace=True)\n",
    "\n",
    "    # If yes and only one, extract the date\n",
    "    elif kaggle_data.shape[0] == 1 :\n",
    "        #print(\"change\")\n",
    "        Movie_Data.loc[index,\"Release date\"] = kaggle_data.iloc[0][\"release_date\"]\n",
    "\n",
    "    # If multiple movies have this name in the Kaggle dataset, compare with the incomplete date of the CMU dataset\n",
    "    else :\n",
    "        date = Movie_Data_date_wrong.loc[index, \"Release date\"]\n",
    "\n",
    "        # If not the same year and not the year in the CMU, drop\n",
    "        if pd.isna(date) or len(date) < 4 :\n",
    "            Movie_Data.drop([index],inplace=True)\n",
    "\n",
    "        # Else, compare\n",
    "        else :\n",
    "            kaggle_data = kaggle_data[kaggle_data['release_date'].str[:4] == date[0:4]]\n",
    "\n",
    "            # Found only 1 movie this year ? extract the date !\n",
    "            if kaggle_data.shape[0] == 1 :\n",
    "                #print(\"found!\")\n",
    "                Movie_Data.loc[index,\"Release date\"] = kaggle_data.iloc[0][\"release_date\"]\n",
    "\n",
    "            # Give up\n",
    "            else :\n",
    "                #print(\"sad..\")\n",
    "                Movie_Data.drop([index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Box office revenue</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Thriller, Science Fiction, Horror, Adventure, ...</td>\n",
       "      <td>set in the second half of the 22nd century, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6631279</th>\n",
       "      <td>Little city</td>\n",
       "      <td>1997-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Romantic comedy, Ensemble Film, Comedy-drama, ...</td>\n",
       "      <td>adam, a san francisco-based artist who works a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77856</th>\n",
       "      <td>Mary Poppins</td>\n",
       "      <td>1964-08-27</td>\n",
       "      <td>102272727.0</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Children's/Family, Musical, Fantasy, Comedy, D...</td>\n",
       "      <td>the film opens with mary poppins  perched in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21926710</th>\n",
       "      <td>White on Rice</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Romantic comedy, Romance Film, Comedy, Indie</td>\n",
       "      <td>jimmy ([[hiroshi watanabe  loves dinosaurs and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156558</th>\n",
       "      <td>Baby Boy</td>\n",
       "      <td>2001-06-27</td>\n",
       "      <td>29381649.0</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Crime Fiction, Drama, Coming of age</td>\n",
       "      <td>a young 20-year-old named jody  lives with his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011340</th>\n",
       "      <td>Dot.Kill</td>\n",
       "      <td>2005-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Thriller, Crime Thriller, Action, Psychologica...</td>\n",
       "      <td>charlie daines , is a morphine-addicted detect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761830</th>\n",
       "      <td>Spaced Invaders</td>\n",
       "      <td>1990-04-27</td>\n",
       "      <td>15369573.0</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Alien Film, Science Fiction, Family Film, Come...</td>\n",
       "      <td>the space armada from mars, known as the imper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918494</th>\n",
       "      <td>State and Main</td>\n",
       "      <td>2000-08-26</td>\n",
       "      <td>6944471.0</td>\n",
       "      <td>Italian Language, English Language</td>\n",
       "      <td>France, United States of America</td>\n",
       "      <td>Parody, Americana, Comedy</td>\n",
       "      <td>havoc is wrought on the inhabitants of a small...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664006</th>\n",
       "      <td>Guilty as Sin</td>\n",
       "      <td>1993-06-04</td>\n",
       "      <td>22886222.0</td>\n",
       "      <td></td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Thriller, Erotic thriller, Psychological thril...</td>\n",
       "      <td>jennifer haines  is an up-and-coming chicago a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35228177</th>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Drama</td>\n",
       "      <td>two former national oceanic atmospheric admini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17077 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Movie name Release date  Box office revenue  \\\n",
       "Wikipedia movie ID                                                              \n",
       "975900                        Ghosts of Mars   2001-08-24          14010832.0   \n",
       "6631279                          Little city   1997-04-04                 NaN   \n",
       "77856                           Mary Poppins   1964-08-27         102272727.0   \n",
       "21926710                       White on Rice   2009-05-31                 NaN   \n",
       "156558                              Baby Boy   2001-06-27          29381649.0   \n",
       "...                                      ...          ...                 ...   \n",
       "25011340                            Dot.Kill   2005-03-08                 NaN   \n",
       "7761830                      Spaced Invaders   1990-04-27          15369573.0   \n",
       "1918494                       State and Main   2000-08-26           6944471.0   \n",
       "664006                         Guilty as Sin   1993-06-04          22886222.0   \n",
       "35228177            Mermaids: The Body Found   2011-03-19                 NaN   \n",
       "\n",
       "                                             Languages  \\\n",
       "Wikipedia movie ID                                       \n",
       "975900                                English Language   \n",
       "6631279                               English Language   \n",
       "77856                                 English Language   \n",
       "21926710                                                 \n",
       "156558                                English Language   \n",
       "...                                                ...   \n",
       "25011340                                                 \n",
       "7761830                               English Language   \n",
       "1918494             Italian Language, English Language   \n",
       "664006                                                   \n",
       "35228177                              English Language   \n",
       "\n",
       "                                           Countries  \\\n",
       "Wikipedia movie ID                                     \n",
       "975900                      United States of America   \n",
       "6631279                     United States of America   \n",
       "77856                       United States of America   \n",
       "21926710                    United States of America   \n",
       "156558                      United States of America   \n",
       "...                                              ...   \n",
       "25011340                    United States of America   \n",
       "7761830                     United States of America   \n",
       "1918494             France, United States of America   \n",
       "664006                      United States of America   \n",
       "35228177                    United States of America   \n",
       "\n",
       "                                                               Genres  \\\n",
       "Wikipedia movie ID                                                      \n",
       "975900              Thriller, Science Fiction, Horror, Adventure, ...   \n",
       "6631279             Romantic comedy, Ensemble Film, Comedy-drama, ...   \n",
       "77856               Children's/Family, Musical, Fantasy, Comedy, D...   \n",
       "21926710                 Romantic comedy, Romance Film, Comedy, Indie   \n",
       "156558                            Crime Fiction, Drama, Coming of age   \n",
       "...                                                               ...   \n",
       "25011340            Thriller, Crime Thriller, Action, Psychologica...   \n",
       "7761830             Alien Film, Science Fiction, Family Film, Come...   \n",
       "1918494                                     Parody, Americana, Comedy   \n",
       "664006              Thriller, Erotic thriller, Psychological thril...   \n",
       "35228177                                                        Drama   \n",
       "\n",
       "                                                                 Plot  \n",
       "Wikipedia movie ID                                                     \n",
       "975900              set in the second half of the 22nd century, th...  \n",
       "6631279             adam, a san francisco-based artist who works a...  \n",
       "77856               the film opens with mary poppins  perched in a...  \n",
       "21926710            jimmy ([[hiroshi watanabe  loves dinosaurs and...  \n",
       "156558              a young 20-year-old named jody  lives with his...  \n",
       "...                                                               ...  \n",
       "25011340            charlie daines , is a morphine-addicted detect...  \n",
       "7761830             the space armada from mars, known as the imper...  \n",
       "1918494             havoc is wrought on the inhabitants of a small...  \n",
       "664006              jennifer haines  is an up-and-coming chicago a...  \n",
       "35228177            two former national oceanic atmospheric admini...  \n",
       "\n",
       "[17077 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movie_Data \n",
    "# Nice we kept 4000 more data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are thus left with: 17077 movies.\n"
     ]
    }
   ],
   "source": [
    "# We are thus left with:\n",
    "print(\"We are thus left with: {} movies.\".format(len(Movie_Data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Date = Movie_Data[\"Release date\"].str[:4].astype(int)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Date, bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Release Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Looks nice ! no outliers :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data \n",
    "Movie_Data.to_csv(clean+\"/Movie_Data_clean.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Real World Violence Dataset\n",
    "\n",
    "To be able to build analysis on real-violence we need additional data. We chose to keep two datasets that complement each other : GVD and NIBRS. The first provides an overview of violent deaths per year from 2004 to 2021, while the latter gives much more granular information. The aim is to pinpoint interesting set of years to dweleve in with NIBRS dataset, while having an overview thanks to GVD one. \n",
    "\n",
    "\n",
    "1.⁠ ⁠**GVD, Global Violent Deaths :** Aggregates violent deaths annually.\n",
    "    -Source : https://www.smallarmssurvey.org/database/global-violent-deaths-gvd\n",
    "   - Description : Aggregated and validated data on violent deaths per country and per year with additional information such as sex and indicator (eg. intentional homicide). \n",
    "\n",
    "*Data preprocessing step for GVD*: \n",
    "We will apply the following pipeline:\n",
    "<ul>\n",
    "<li>Load GVD entire dataset</li>\n",
    "<li>Filter and keep only USA related data </li>\n",
    "<li>Remove all unecessary columns (eg. country_name)</li> \n",
    "<li>Remove uninentional homicide since we are interested only in violent interactions that are intentional </li>\n",
    "</ul>\n",
    "    \n",
    "2.⁠ **NIBRS, National Incident-Based Reporting System :** Offers daily-level crime data \n",
    "   -Source: https://cde.ucr.cjis.gov/LATEST/webapp/#/pages/downloads\n",
    "   -Description : Reported crimes to the FBI per state and per year with detailed information such as victims related ones, crime and so on. \n",
    "   - NIBRS data offers more precise informations about daily crimes as it provides the precise date of an incident. \n",
    "   - Each incident can easily be classified in order to keep only violent crimes.\n",
    "   - To go further, NIBRS can provide victim's injury, incident circumstances and if weapons were used during the incident.\n",
    "  \n",
    "*Data preprocessing step for NIBRS*\n",
    "We have applied the following step in order to have well-formated and useful data:\n",
    "<ul>\n",
    "<li>For each state all the yearly data need to be downloaded and stored with the following protocol: \n",
    "  \n",
    "\n",
    "Name_of_the_state folder\\\n",
    "├── XX-year1\\\n",
    "├── XX-year2\\\n",
    "├── XX-year3\\\n",
    "...\n",
    "</li>\n",
    "\n",
    "<li>⁠Iteration on each XX-year folder in order to modify in lowercase all the name and label of each file.</li>\n",
    "<li>⁠Merging of useful parameters:<ul>\n",
    "<li>incident_id ⁠: unique identifier of each incident</li>\n",
    "<li>incident_date ⁠: precise date of the incident</li>\n",
    "<li>offense_type_id ⁠: type of offense of the incident</li>\n",
    "<li>Help to get ⁠ offense_name ⁠ (e.g., Assault Offenses, Homicide Offenses)</li>\n",
    "<li>Help to get ⁠ crime_against ⁠ (e.g., Society, Person)</li>\n",
    "<li>arrestee_id ⁠: identifier of the arrestee</li>\n",
    "<li>weapon_id ⁠: identifier of the weapon used (if one was used)</li>\n",
    "<li>victim_id ⁠: identifier of the victim</li>\n",
    "<li>injury_id ⁠: identifier of victim injury</li>\n",
    "<li>circumstances_id ⁠: identifier of circumstances related to the incident</li>\n",
    "    </ul></li>\n",
    "<li>Data cleaning:⁠<ul>\n",
    "  <li> Keep only incidents with violent ⁠ offense_name⁠</li>\n",
    "  <li> Keep only incidents with ⁠ crime_against ⁠ = Person</li></ul></li>\n",
    "<li>Save the cleaned dataset</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 0.2.1 FBI NIBRS database\n",
    "\n",
    "You'll find the entire database [here](https://www.dolthub.com/repositories/Liquidata/fbi-nibrs/data/main) to help to visualize the entire data.\n",
    "\n",
    "The downloaded data comes from the [**FBI Crime Data Explorer**](https://cde.ucr.cjis.gov/LATEST/webapp/#/pages/downloads).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'merge_offense_types' from 'src.data.FBI_merging' (/home/jen/Documents/EPFL/ADA/ada-2024-project-alligatorsdontapologize24/src/data/FBI_merging.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#import src.data.FBI_analysis\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFBI_preprocess_folder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_files_in_directory\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFBI_merging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_state_data,merge_offense_types\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#from FBI_analysis import analyze_incidents_and_missing_values,analyze_offenses\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFBI_cleaning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filter_violent_offenses\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'merge_offense_types' from 'src.data.FBI_merging' (/home/jen/Documents/EPFL/ADA/ada-2024-project-alligatorsdontapologize24/src/data/FBI_merging.py)"
     ]
    }
   ],
   "source": [
    "#import relative script \n",
    "import src.data.FBI_cleaning\n",
    "import src.data.FBI_merging\n",
    "#import src.data.FBI_analysis\n",
    "\n",
    "from src.data.FBI_preprocess_folder import preprocess_files_in_directory\n",
    "from src.data.FBI_merging import process_state_data,merge_offense_types\n",
    "#from FBI_analysis import analyze_incidents_and_missing_values,analyze_offenses\n",
    "from src.data.FBI_cleaning import filter_violent_offenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 0.2.1.1 load and merge the data (Alabama, as a first example)\n",
    "\n",
    "In order to have all reported incidents for a given state, we have the merge multiple datafiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**\n",
    "\n",
    "It is needed to do a preprocessing on each state folder in order to have only lowercase in the folder and label name. The function `preprocess_files_in_directory()` directly modify the folder name and labels in each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory where Alabama data is stored\n",
    "state_dir = raw +'/Alabama'\n",
    "\n",
    "# Run the function to preprocess all files in the Alabama directory\n",
    "preprocess_files_in_directory(state_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Merging interesting data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file\n",
    "output_file = os.path.join(state_dir, 'Alabama_merged_data.csv')\n",
    "\n",
    "# Process data for the state and save it\n",
    "final_data = process_state_data(state_dir, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's visualize the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(FBI_analysis)\n",
    "\n",
    "# Analyze and visualize the incidents and missing values per column\n",
    "analyze_incidents_and_missing_values(final_data, 'incident_date', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Analysis Summary**\n",
    "From the bar plots, we observe the following:\n",
    "\n",
    "1. **Data concentration in 1991 and 1992:**\n",
    "   - The majority of the data is concentrated in the years 1991 and 1992, with very limited data for other years. This may limit the temporal analysis but provides a strong starting point for studying patterns in these two years.\n",
    "   - Further investigation across other states might help fill in data gaps for a more comprehensive view.\n",
    "2. **Missing `incident_date` values:**\n",
    "   - A few `incident_date` values are missing, specifically 14280. Despite these missing dates, the remaining data is largely complete.\n",
    "3. **Availability of `offense_type_id`:**\n",
    "    - All offense types are available, which is good for categorizing offenses based on our criteria for violence. This will help us to classify offenses and filter incidents related to violent behavior.\n",
    "4. **Missing Data for Specific Parameters:**\n",
    "    - Four key columns (`arrestee_id`, `weapon_id`, `injury_id`, and `circumstances_id`) show a significant number of missing values, as indicated in the NaN count plot.\n",
    "    - We hope additional data from other states can fill in some of these gaps. However, since offense types are available, we can still proceed with classification based on offenses alone.\n",
    "5. **Insights on Weapons and Injuries:**\n",
    "    - The weapon_id and injury_id columns, though missing some values, provide information on the type and severity of violence. While this missing data presents some limitations, the existing offense data could compensate.\n",
    "\n",
    "So, despite some missing values in specific columns, the precise date of the incident, the available offense data and partial details on weapons and injuries can provide a solid foundation for analyzing violent incidents. We can refine our approach further as more data becomes available from additional states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory where Alabama data is stored\n",
    "base_dir = '../../data/RAW/Alabama'\n",
    "state_prefix = 'AL'\n",
    "\n",
    "# Analyze and visualize the offenses\n",
    "analyze_offenses(final_data, base_dir, state_prefix, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Offense Types**\n",
    "\n",
    "From the bar plots, we can say:\n",
    "\n",
    "1. **Unique offense types in `State_merged_data`:**\n",
    "    - The first plot shows the number of unique offense types present in the `State_merged_data`, in our example Alabama. We observe that a subset of approximately 45 unique offenses is available in the data.\n",
    "    - This means that the majority of incidents fall into well-defined and recurring offense categories. It will help us to categorize incidents reliably based on these established classifications.\n",
    "2. **Top 10 Most Frequent Offense Types:**\n",
    "    - The second plot displays the top 10 most frequently cited offense types in the dataset, along with their occurrence counts. Offenses like *Burglary/Breaking & Entering*, *All Other Larceny*, and *Simple Assault* are the most common.\n",
    "    - These recurring offenses serve as strong indicators for our analysis, particularly for categorizing incidents as violent or non-violent.\n",
    "  \n",
    "In summary, the offenses available in the NIBRS data for Alabama are not only varied but also recurrent, which provides a reliable basis for violent incident classification. The top 10 offenses illustrate the primary incident types and should help us for further analysis focused on identifying patterns of violent behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 0.2.1.2 Clean the data (the case of Washington)\n",
    "\n",
    "After loading and merging the data for one state, we need to clean the data. We will use the case of the state of Washington"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the washington data\n",
    "WA_data_example = pd.read_csv(raw+\"/Washington/Washington_merged_data.csv\", index_col=0)\n",
    "WA_data_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to clean the data, we will use data that gives `offense_type`. To do so, we have to iterate through the years to get all offense types. We save the results in `offense_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(FBI_merging)\n",
    "\n",
    "offense_data = merge_offense_types(raw +'/Washington', 'WA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean a state data (in our example Washington), we have to keep only violent incidents. As a proof of concept, we will only focus on 2 parameters used in `offense_data`:\n",
    "-  crime against a `Person`\n",
    "-  violent categories found in `offense_category_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize offense_data\n",
    "offense_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of violent categories and targets used in filter_violent_offenses\n",
    "# violent_categories = [\n",
    "#         \"Assault Offenses\", \"Homicide Offenses\", \"Sex Offenses\", \"Kidnapping/Abduction\", \"Animal Cruelty\"]\n",
    "#     violent_targets = [\"Person\"]  # Offenses against a person\n",
    "\n",
    "# Clean the data by filtering out non-violent offenses\n",
    "WA_cleaned_data = filter_violent_offenses(WA_data_example, offense_data)\n",
    "\n",
    "# Save the cleaned data\n",
    "state_clean_dir = clean\n",
    "output_file = os.path.join(state_clean_dir, 'Washington_cleaned_data.csv')\n",
    "\n",
    "WA_cleaned_data.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WA_cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison before/after cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(FBI_analysis)\n",
    "\n",
    "# Analyze and visualize the incidents and missing values per column\n",
    "analyze_incidents_and_missing_values(WA_data_example, 'incident_date', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and visualize the incidents and missing values per column\n",
    "analyze_incidents_and_missing_values(WA_cleaned_data, 'incident_date', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory where Alabama data is stored\n",
    "base_dir = raw +'/Washington'\n",
    "state_prefix = 'WA'\n",
    "\n",
    "# Analyze and visualize the offenses\n",
    "analyze_offenses(WA_cleaned_data, base_dir, state_prefix, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot shows that the majority of incidents fall into well-defined and recurring offense categories. It will help us to categorize incidents reliably based on these established classifications\n",
    "\n",
    "The second plot shows that the top 10 most reccurent violent offense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 0.2.2 GVD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GVD dataset\n",
    "GVD_data = pd.read_csv(raw+'GVD_Dataset/2023_gvdDatabase_1_0_country.csv')\n",
    "\n",
    "# Select only american data \n",
    "GVD_usa = GVD_data[GVD_data['country_code'] == 'USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that are no longer needed\n",
    "columns_to_remove = [\"country_code\",\"country_name\",\"country_region\", \"country_subregion\"]\n",
    "GVD_usa = GVD_usa.drop(columns=columns_to_remove)\n",
    "GVD_usa_voluntary = GVD_usa[GVD_usa.indicator != \"Homicide unintentional\"]\n",
    "#GVD_usa_voluntary.to_csv(clean+\"GVD_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different dataframe for each population to analyse potential biais in the data\n",
    "GVD_usa =GVD_data[GVD_data.country_code == \"USA\"]\n",
    "GVD_female = GVD_usa[GVD_usa.population == \"Female\"]\n",
    "GVD_male = GVD_usa[GVD_usa.population == \"Male\"]\n",
    "GVD_all = GVD_usa[GVD_usa.population == \"Total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GVD_all_homicide =GVD_all[(GVD_all.mechanism== \"All\") & (GVD_all.indicator == \"Homicide intentional\")]\n",
    "GVD_all_violent_death =GVD_all[(GVD_all.mechanism== \"All\") & (GVD_all.indicator == \"Violent death\")]\n",
    "\n",
    "# Plot the number of inentional homicides and violent per year in the USA\n",
    "fig, axes = plt.subplots(1,2,figsize=(18, 5),sharey=True)\n",
    "sns.barplot(ax=axes[0], x=\"year\", y=\"count\",hue=\"year\", data=GVD_all_homicide)\n",
    "axes[0].set_title(\"Intentional Homicides in the USA\")\n",
    "axes[0].set_xlabel(\"Year\")\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "axes[0].set_ylabel(\"Number of deaths per category\")\n",
    "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "sns.barplot(ax=axes[1], x=\"year\", y=\"count\",hue=\"year\", data=GVD_all_violent_death)\n",
    "axes[1].set_title(\"Violent Deaths in the USA\")\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "axes[1].set_xlabel(\"Year\")\n",
    "axes[1].legend(\"\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are surprised by the higher number of violent deaths compared to intentional homicide. This will require further investigation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that entry comment enable to have any idea of the reliability of the data. The following comments were points that we wished to investigate further : \n",
    "\n",
    "'Data interpolated using a linear approximation in the 2023 update.',\n",
    "'Data estimated using a global multiplier in the 2023 update.',\n",
    "'Data estimated using a subregional average in the 2023 update.',\n",
    "'Data estimated in the 2023 update.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 0.3 Human labelled data\n",
    "\n",
    "For your project, we needed to assign to each movie a violence level. We therefore performed a human-labelling steps to create a training/validation set. This data also need to be cleaned.\n",
    "\n",
    "<b> First step: labelling the Data </b> \\\n",
    "Since labeled data is required for analysis, we manually labeled a subset of the dataset. We divided part of the data among team members and, to ensure the subjectivity of the labeling process, we had some plots labeled multiple times by external participants. Each movie plot was classified based on a categorical scale:\n",
    "<ul>\n",
    "    <li><b>-1</b> : Peaceful</li>\n",
    "    <li><b>0</b> : Mild</li>\n",
    "    <li><b>1</b> : Violent</li>\n",
    "</ul>\n",
    "\n",
    "<b>Data preprocessing steps</b> \\\n",
    "We will apply the following pipeline:\n",
    "\n",
    "<ul>\n",
    "    <li>load The data</li>\n",
    "    <li>Assess the subjectivity of the data</li>\n",
    "    <li>Make each label unique</li>\n",
    "    <li>Save the data</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the labelled data\n",
    "ViolentLabel,ViolentData = data_loader.human_labelled_data(\"Raw\")\n",
    "display(ViolentLabel)\n",
    "display(ViolentData.head())\n",
    "# LAST is  boolean to recognize the point we added to help the analysis, more explanation after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3.1 Assess subjectivity and clean the data\n",
    "\n",
    "Some data have been labelled several times by several people, to assess the subjectivity of the labelling task. \\\n",
    "Let's visualize the data.\n",
    "Here we will plot only datapoint that have been labelled at least 2 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DataBefore = ViolentData[ViolentData[\"LAST\"] == 0]\n",
    "duplicated_data = DataBefore[DataBefore.index.duplicated(keep=False)]\n",
    "\n",
    "# Plot all duplicates in one figure with side-by-side boxplots\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=duplicated_data, x=\"Wikipedia movie ID\", y=\"Answer\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Box Plot of 'Answer' by Duplicated Wikipedia IDs\")\n",
    "plt.xlabel(\"Wikipedia ID\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Answer Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have\",len(DataBefore.index.unique()),\"labelled plots\")\n",
    "print(\"We have\",len(duplicated_data.index.unique()),\"duplicated labelling\")\n",
    "print(\"We have\",(duplicated_data.groupby(\"Wikipedia movie ID\")[\"Answer\"].nunique() > 1).sum(),\"datapoint with different labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DataBefore.groupby(\"Wikipedia movie ID\").size().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is more difficult than expected ! \\\n",
    "A majority of duplicated labelling show the same output. However, we have different value for 24 points.\n",
    "Additionnaly, for 3 points we have the 3 answers ! We will take a closer look to this point and to the point with opposite labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OppositeLabels = duplicated_data.groupby(\"Wikipedia movie ID\").filter( lambda group: set([-1, 1]).issubset(group[\"Answer\"].unique()))\n",
    "\n",
    "# Plot all duplicates in one figure with side-by-side boxplots\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.swarmplot(data=OppositeLabels, x=\"Wikipedia movie ID\", y=\"Answer\", size=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Movie with opposite labels\")\n",
    "plt.xlabel(\"Wikipedia ID\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Answer Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot in Movie_Data.loc[OppositeLabels.index.unique()][\"Plot\"] :\n",
    "    display(plot)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can distinguish 3 types of datapoints :\n",
    "- have been labeled multiple times with always the same label : We keep this label.\n",
    "- have been labeled multiple times with different labels but the mean is closer to 1 label (example 3 labels (0,0,1)) : we could keep the label closest to the mean, we will take a deep look and relabel if necessary.\n",
    "- have been labeled multiple times with different labels and the mean is exactly between 2 labels : We will take a closer look and re-label by another person.\n",
    "\n",
    "After relabelling, here is the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicated_data_clean = ViolentData[ViolentData.index.duplicated(keep=False)]\n",
    "\n",
    "# Plot all duplicates in one figure with side-by-side boxplots\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=duplicated_data_clean, x=\"Wikipedia movie ID\", y=\"Answer\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Box Plot of 'Answer' by Duplicated Wikipedia IDs\")\n",
    "plt.xlabel(\"Wikipedia ID\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Answer Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViolentData.groupby(\"Wikipedia movie ID\").size().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalData = ViolentData.groupby(\"Wikipedia movie ID\")[\"Answer\"].median().to_frame()\n",
    "FinalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalData[~FinalData[\"Answer\"].isin([-1, 0, 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labelling step is done ! We save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_loader.save_back_to_excel(ViolentLabel, FinalData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Movie data analysis\n",
    "\n",
    "Now starts the characterization of our movies. First, we want to look into the plots and count how many violent words appear in the summary. \\\n",
    "Here, two things are worth notice: \n",
    "1. The list of words is souced from the web and agumented by us, for more completeness. Therefore, there is some subjectivity on our violence score: it depends on which terms we added. To know more about it see <span style=\"color:red\"> physical_violence_words_justifications.txt </span> & <span style=\"color:red\">psychological_violence_words_justifications</span> in the data/CLEAN/violent_word_list folder.\n",
    "2. The summaries are not all the same length. Hence, we use the density of violent words in the plots to characterize violence. \n",
    "\n",
    "Here we start with the generic list of violent words. Then we will have a list for words related to psychological violence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.1 Generic violent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the selected words for our first list (physical violence)\n",
    "violent_word_list = data_loader.Violent_word_list(\"Physical_violence\")\n",
    "print(violent_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put the list to a Pandas Dataframe\n",
    "violence_list = pd.DataFrame(violent_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an excel out of the list, so that if we want to modify it later we don't need to come back inside the code\n",
    "# violence_list.to_excel(clean+\"/violent_word_list/Physical_violence.xlsx\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.2 Violent words related to psychology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the selected words for our second list (psychological violence)\n",
    "psycho_violence_list = data_loader.Violent_word_list(\"Psychological_violence\")\n",
    "print(psycho_violence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put the list to a Pandas Dataframe\n",
    "psycho_list = pd.DataFrame(psycho_violence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an excel out of the list, so that if we want to modify it later we don't need to come back inside the code\n",
    "#psycho_list.to_excel(clean+\"/violent_word_list/Psychological_violence.xlsx\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.3 Analysis of the outcome of violent words density in summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the WordCounter class to investigate the density of violent words in the summaries\n",
    "\n",
    "# Now you can import the script like a module\n",
    "from Word_counter import WordCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Wordcounter see file Word_counter.py. We can either use one list only, with the keywords _Physical_violence_ & _Psychological_violence_, or all lists with keyword _All_. Note that, with this method if non-existing keywords are given as inputs, the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Counter = WordCounter(data_loader, Movie_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the count of violent words (both )\n",
    "Count_violent = Word_Counter.violent_word_count(\"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We look at our results\n",
    "Count_violent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the 40 most violent (physically) movies \n",
    "\n",
    "# First we sort the values\n",
    "Count_violent_sorted_physical = Count_violent.sort_values(by='density word_count_Physical_violence', ascending=False)\n",
    "\n",
    "# We retreive the movie name from the Movie_Data dataframe\n",
    "indices_physical_violence = Count_violent_sorted_physical.head(40).index\n",
    "movie_names = Movie_Data.loc[indices_physical_violence, 'Movie name']\n",
    "density_physical_violence = Count_violent_sorted_physical.head(40)['density word_count_Physical_violence']\n",
    "\n",
    "# We do the same but for the words\n",
    "Count_violent_sorted_physical_by_words = Count_violent.sort_values(by='word_count_Physical_violence', ascending=False)\n",
    "indices_physical_violence_by_words = Count_violent_sorted_physical_by_words.head(40).index\n",
    "movie_names_by_words = Movie_Data.loc[indices_physical_violence_by_words, 'Movie name']\n",
    "physical_violence_by_words = Count_violent_sorted_physical_by_words.head(40)['word_count_Physical_violence']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "sns.barplot(x=movie_names, y=density_physical_violence, ax=ax1)\n",
    "ax1.set_xlabel(\"Movie Name\")\n",
    "ax1.set_ylabel(\"Violent words density\")\n",
    "ax1.tick_params(axis='x', rotation=90)\n",
    "\n",
    "sns.barplot(x=movie_names_by_words, y=physical_violence_by_words,  ax=ax2)\n",
    "ax2.set_xlabel(\"Movie Name\")\n",
    "ax2.set_ylabel(\"Violent words count\")\n",
    "ax2.tick_params(axis='x', rotation=90)\n",
    "fig.suptitle(\"Physical violence ranking of movies (top 40)\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the 40 most violent (psychologically) movies \n",
    "\n",
    "# First we sort the values\n",
    "Count_violent_sorted_psycho = Count_violent.sort_values(by='density word_count_Psychological_violence', ascending=False)\n",
    "\n",
    "# We retreive the movie name from the Movie_Data dataframe\n",
    "indices_psycho_violence = Count_violent_sorted_psycho.head(40).index\n",
    "movie_names = Movie_Data.loc[indices_psycho_violence, 'Movie name']\n",
    "density_psycho_violence = Count_violent_sorted_psycho.head(40)['density word_count_Psychological_violence']\n",
    "\n",
    "# We do the same but for the words\n",
    "Count_violent_sorted_psycho_by_words = Count_violent.sort_values(by='word_count_Psychological_violence', ascending=False)\n",
    "indices_psycho_violence_by_words = Count_violent_sorted_psycho_by_words.head(40).index\n",
    "movie_names_by_words = Movie_Data.loc[indices_psycho_violence_by_words, 'Movie name']\n",
    "psycho_violence_by_words = Count_violent_sorted_psycho_by_words.head(40)['word_count_Psychological_violence']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "sns.barplot(x=movie_names, y=density_psycho_violence, ax=ax1)\n",
    "ax1.set_xlabel(\"Movie Name\")\n",
    "ax1.set_ylabel(\"Violent words density\")\n",
    "ax1.tick_params(axis='x', rotation=90)\n",
    "\n",
    "sns.barplot(x=movie_names_by_words, y=psycho_violence_by_words,  ax=ax2)\n",
    "ax2.set_xlabel(\"Movie Name\")\n",
    "ax2.set_ylabel(\"Violent words count\")\n",
    "ax2.tick_params(axis='x', rotation=90)\n",
    "fig.suptitle(\"Psychological violence ranking of movies (top 40)\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retreive the genre for most physically & psychologically violent movies\n",
    "\n",
    "# Count genres appearances\n",
    "movie_genres_physical = Movie_Data.loc[indices_physical_violence, 'Genres'].value_counts()\n",
    "movie_genres_psycho = Movie_Data.loc[indices_psycho_violence, 'Genres'].value_counts()\n",
    "\n",
    "# Group by the counts\n",
    "genres_physical_more_once = movie_genres_physical[movie_genres_physical > 1]\n",
    "genres_physical_once = movie_genres_physical[movie_genres_physical == 1]\n",
    "\n",
    "genres_psycho_more_once = movie_genres_psycho[movie_genres_psycho > 1]\n",
    "genres_psycho_once = movie_genres_psycho[movie_genres_psycho == 1]\n",
    "\n",
    "# Prepare for plotting\n",
    "labels_physical = list(genres_physical_more_once.index) + [\"Others\"]\n",
    "heights_physical = list(genres_physical_more_once.values) + [1]\n",
    "\n",
    "labels_psycho = list(genres_psycho_more_once.index) + [\"Others\"]\n",
    "heights_psycho = list(genres_psycho_more_once.values) + [1]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "ax1.bar(labels_physical, heights_physical, edgecolor='black')\n",
    "ax1.set_ylabel('Counts')\n",
    "ax1.set_title('Frequency Physical Violence Terms')\n",
    "\n",
    "ax2.bar(labels_psycho, heights_psycho, edgecolor='black')\n",
    "ax2.set_ylabel('Counts')\n",
    "ax2.set_title('Frequency Psychological Violence Terms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.4 Sentiment Analysis\n",
    "\n",
    "In this section, we will apply the DistillBERT sentiment analysis model to the clean dataset and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the script like a module\n",
    "import DistillBERT_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "data_loader = DataLoader(raw,clean)\n",
    "\n",
    "# Are we working on the test set\n",
    "Test_set_data = True\n",
    "# Run everything again ? \n",
    "Run = False\n",
    "\n",
    "if Test_set_data :\n",
    "    MovieData = data_loader.plot_data()\n",
    "    MovieName = data_loader.movie_data()[\"Movie name\"]\n",
    "    ViolentLabel, ViolentData = data_loader.human_labelled_data()\n",
    "    MovieData = MovieData.loc[ViolentData.index.unique()]\n",
    "    MovieData = pd.merge(MovieData,MovieName, left_index=True, right_index=True,how=\"inner\")\n",
    "else :\n",
    "    MovieData = data_loader.clean_movie_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run :\n",
    "    # Lists to accumulate rows for efficiency\n",
    "    sentiment_data = []\n",
    "    \n",
    "    detector = DistillBERT_emotion.ViolenceDetector()\n",
    "    i = 0\n",
    "    for index,row in MovieData.iterrows():\n",
    "        if i%1000 ==0:\n",
    "            print(i)\n",
    "        result = detector.analyze_violence(row[\"Plot\"])\n",
    "    \n",
    "        sentiment_data.append({\n",
    "                \"Wikipedia movie ID\": index,\n",
    "                \"name\" : row[\"Movie name\"],\n",
    "                \"sadness\": result[0],\n",
    "                \"joy\": result[1],\n",
    "                \"love\": result[2],\n",
    "                \"anger\": result[3],\n",
    "                \"fear\": result[4],\n",
    "                \"surprise\": result[5]\n",
    "            })\n",
    "        i += 1\n",
    "    \n",
    "    Sentiment = pd.DataFrame(sentiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run : \n",
    "    # Save the result\n",
    "    if Test_set_data : \n",
    "        Sentiment.to_csv(clean + \"/sentiment_test.csv\") \n",
    "    else : \n",
    "        Sentiment.to_csv(clean + \"/sentiment.csv\") \n",
    "else :\n",
    "    SentimentData, SentimentDataTest = data_loader.load_sentiment()\n",
    "    if Test_set_data :\n",
    "        Sentiment = SentimentDataTest\n",
    "    else :\n",
    "        Sentiment = SentimentData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentiment = Sentiment.set_index(\"Wikipedia movie ID\")\n",
    "Sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentiment analysis using DistillBERT_emotion\n",
    "\n",
    "X = 30\n",
    "emotions = [\"sadness\",\n",
    "            \"joy\",\n",
    "            \"love\",\n",
    "            \"anger\",\n",
    "            \"fear\",\n",
    "            \"surprise\"]\n",
    "\n",
    "# Create a figure with subplots (1x3 grid)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16,12))\n",
    "\n",
    "# Set a title for the entire figure\n",
    "fig.suptitle('Top Emotion Scores for Movies', fontsize=16)\n",
    "\n",
    "for i in range(0,len(emotions)):\n",
    "    \n",
    "    # Plot for Sadness with vertical x labels\n",
    "    sns.barplot(x='name', y=emotions[i], data=Sentiment.sort_values(emotions[i],ascending=False).iloc[0:min(X,Sentiment.shape[0])],ax=axes[i//3, i%3])\n",
    "    axes[i//3, i%3].set_title(f'Top {emotions[i].capitalize()} Scores')\n",
    "    axes[i//3, i%3].set_xlabel('Movie ID')\n",
    "    axes[i//3, i%3].set_ylabel(f'{emotions[i].capitalize()} Score')\n",
    "\n",
    "    axes[i//3, i%3].set_xticks(range(min(X,Sentiment.shape[0])))  # Ensure ticks are set\n",
    "    axes[i//3, i%3].set_xticklabels(axes[i//3, i%3].get_xticklabels(), rotation=90)\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to classify movies into violent or non-violent? \n",
    "\n",
    "Now that we have a better idea of what our movies look like from the analysis of their plot, we would like to classify them into non-violent, mild and violent. \\\n",
    "To do that, we will use surely the results previously obtained from the plots. However we ask ourselves: how do we combine the results from the psychological violence and the physical violence terms? \\\n",
    "To answer this question we decided to include a sentiment analysis of our plots, and to use the latter together with the results obtained from the plots to create a regression model. By doing this we can infer the weights of each feature for our model. Hence, we humanly-labelled 100 summaries and used those as training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.1 Violent movies finder: the regression model\n",
    "\n",
    "<b> The Model </b> \\\n",
    "For simplicity, we chose to perform a logistic regression using several selected features.\n",
    "\n",
    "\n",
    "<b> The features </b> \\\n",
    "The selected feature set includes:\n",
    "<ul>\n",
    "    <li><b>Word Count Features</b>\n",
    "        <ul> \n",
    "            <li>Count of physically violent words</li> \n",
    "            <li>Count of psychologically violent words</li> \n",
    "            <li>Density of physically violent words</li> \n",
    "            <li>Density of psychologically violent words</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Sentimental Analysis Features</b>\n",
    "       <ul>\n",
    "           <li>Sadness</li>\n",
    "           <li>Joy</li>\n",
    "           <li>Love</li>\n",
    "           <li>Anger</li>\n",
    "           <li>Surprise</li>\n",
    "       </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n",
    "<b> The Dataset </b> \n",
    "<ul>\n",
    "    <li><b>Training and Testing Data</b> <br/> Given the limited number of labeled plots available, we will use most of the labeled items for the training set. We will keep 20% plots as the testing set to evaluate the model (alternatively, we may use the entire dataset and assess labeling quality across the final labeled set) </li>\n",
    "    <li><b>Final Dataset</b>  <br/> We will apply the model to label the entire dataset and review the quality of the labels.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_loader = DataLoader(raw,clean)\n",
    "MovieData,DataTest = data_loader.data_for_violent_model()\n",
    "MovieData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labelled data\n",
    "ViolentLabel,ViolentData = data_loader.human_labelled_data()\n",
    "display(ViolentLabel)\n",
    "display(ViolentData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalSet = MovieData.loc[MovieData.index.difference(ViolentData.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet = pd.merge(DataTest,ViolentData[\"Answer\"],left_index=True,right_index=True,how = \"inner\")\n",
    "TestSet = TestSet.drop([\"Unnamed: 0\"],axis = 1)\n",
    "TestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 0.2\n",
    "\n",
    "# Split the data between train and validation\n",
    "TrainingSet,ValidationSet = train_test_split(TestSet, test_size=fraction, random_state=21)\n",
    "\n",
    "print(TrainingSet.shape[0])\n",
    "print(ValidationSet.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Ridge(alpha=6)\n",
    "#model.fit(TestSet.drop([\"Answer\",\"name\"], axis=1), TestSet[\"Answer\"])\n",
    "\n",
    "#model = LinearRegression()  # create the model\n",
    "#model.fit(TestSet.drop([\"Answer\",\"name\"], axis=1), TestSet[\"Answer\"])  \n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(TrainingSet.drop([\"Answer\",\"name\"], axis=1), TrainingSet[\"Answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"coefficient\",model.coef_)\n",
    "print(\"intercept\",model.intercept_)\n",
    "model.score(TrainingSet.drop([\"Answer\",\"name\"], axis=1), TrainingSet[\"Answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare = pd.DataFrame(model.predict(ValidationSet.drop([\"Answer\",\"name\"], axis=1)),index=ValidationSet.index,columns=[\"Prediction\"])\n",
    "Compare[\"Label\"] = ValidationSet[\"Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(Compare[\"Label\"],Compare[\"Prediction\"])\n",
    "print(\"accuracy\",accuracy*100)\n",
    "\n",
    "m1 = abs(Compare[\"Label\"]-Compare[\"Prediction\"]).mean()\n",
    "print(\"abs distance\",m1)\n",
    "\n",
    "#penalize more if opposite result \n",
    "m2 = np.power(Compare[\"Label\"]-Compare[\"Prediction\"], 2).mean()\n",
    "print(\"pow distance\",m2)\n",
    "\n",
    "print(\"Correct label\",(Compare[\"Label\"]==Compare[\"Prediction\"]).sum())\n",
    "print(\"incorrect but close\",(abs(Compare[\"Label\"]-Compare[\"Prediction\"])==1).sum())\n",
    "print(\"opposite\",(abs(Compare[\"Label\"]-Compare[\"Prediction\"])==2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is not satisfying yet: the accuracy is only 33% and we have too many incorrect but close labels. This is why we decide to turn to LLM models, to see if we obtain better classification for movies’ violence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.2 Classification with LLM\n",
    "\n",
    "We will try to label the data using a LLM, namely GPT4mini from OpenAI . \\\n",
    "We will use the training set from above as the testing set, and keep 20% as a validation set. \n",
    "\n",
    "<b> The Model </b>\n",
    "\n",
    "We will use the GPT-4o-mini model \\\n",
    "https://platform.openai.com/docs/overview \\\n",
    "https://platform.openai.com/docs/models#gpt-4o-mini\n",
    "\n",
    "<b> References </b>\n",
    "\n",
    "https://platform.openai.com/docs/guides/prompt-engineering \\\n",
    "https://medium.com/discovery-at-nesta/how-to-use-gpt-4-and-openais-functions-for-text-classification-ad0957be9b25 \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.2.1 Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "CleanData = data_loader.clean_movie_data()\n",
    "PlotData = data_loader.plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the labelled data\n",
    "ViolentLabel,ViolentData = data_loader.human_labelled_data()\n",
    "display(ViolentLabel.drop([\"Unnamed: 0\"],axis = 1))\n",
    "display(ViolentData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet = pd.merge(ViolentData,PlotData, left_index=True,right_index=True, how = \"inner\")\n",
    "print(\"Number of test point :\",TestSet.shape[0])\n",
    "TestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet.iloc[0][\"Plot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 0.2\n",
    "\n",
    "# Split the data between train and validation\n",
    "TrainingSet,ValidationSet = train_test_split(TestSet, test_size=fraction, random_state=21)\n",
    "\n",
    "print(TrainingSet.shape[0])\n",
    "print(ValidationSet.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 LLM - GPT-4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import the Classifier class\n",
    "from OpenIA_utility import GPT4mini_ViolenceClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "####  2.2.3 Prompt engineering\n",
    "\n",
    "We developed a prompt for the classification task. \\\n",
    "The prompt contains a clear violence scale, where each label (Peaceful,Mild,Violent) in explained, and a clear instruction.\n",
    "\n",
    "To help the model to perform, we add examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init our classifier\n",
    "Classifier = GPT4mini_ViolenceClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Classifier.Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Classifier.Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the model return the result in the good format, we developed a function.\n",
    "\n",
    "The final function is :\n",
    "\n",
    "```ruby\n",
    "        self.function = {\n",
    "           \"name\": \"Assign_violence_level\",\n",
    "           \"description\": \"Predict the level of violence of a list of movie plots\",\n",
    "           \"parameters\": {\n",
    "               \"type\": \"object\",\n",
    "               \"properties\": {\n",
    "                   \"prediction\": {\n",
    "                       \"type\": \"array\",\n",
    "                       \"items\": {\n",
    "                           \"type\": \"string\",\n",
    "                           \"enum\": [\n",
    "                               \"Peaceful\",\n",
    "                               \"Mild\",\n",
    "                               \"Violent\"\n",
    "                           ]\n",
    "                       },\n",
    "                       \"description\": \"The list of violence levels for each movie plot, in the same order as the plots were provided.\"\n",
    "                   }\n",
    "               },\n",
    "               \"required\": [\n",
    "                   \"prediction\"\n",
    "               ]\n",
    "           }\n",
    "        }\n",
    "\n",
    "```\n",
    "\n",
    "The model have to return a array of prediction, one for each plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "####  2.2.4 Verify the number of tokens\n",
    "\n",
    "The model have a maximum number of input tokens ! For our model, the limit is 128000 tokens. For cod efficiency (and money), we would like to avoid having to loop on each plot and recalling the prompt every time. We will look at the number of token to see how many plots we can put at the time. \n",
    "\n",
    "We implemented a function that tokenize a text in the same way as the model and return the number of token and the pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count for the prompt (and example)\n",
    "TotalPromt = Classifier.Prompt_size\n",
    "print(\"For the prompt we have\",TotalPromt,\"tokens, pricing :\",TotalPromt*Classifier.pricing)\n",
    "\n",
    "# Count for the test set\n",
    "TotalTest = TestSet[\"Plot\"].apply(Classifier.count_tokens).sum()\n",
    "print(\"For the test dataset we have\",TotalTest+TotalPromt,\"tokens, pricing :\",TotalTest*Classifier.pricing,\"batch\",int(TotalTest/(Classifier.max_input-TotalPromt)+1))\n",
    "\n",
    "# Count for the whole dataset\n",
    "TotalData = CleanData[\"Plot\"].apply(Classifier.count_tokens).sum()\n",
    "batch = int(TotalData/(Classifier.max_input-TotalPromt))+1\n",
    "print(\"For the whole dataset we have\",TotalData,\"tokens, pricing :\",(TotalData+batch*TotalPromt)*Classifier.pricing,\"batch\",batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will need to split the data into batchs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "####  2.2.5 Create Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we send multiple plot at the time, we need to format them together in a way the model can understand. Here an example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSet.iloc[0][\"Plot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first parameter is the number of the plot, second is the text\n",
    "Classifier.format_plot(0,TrainingSet.iloc[0][\"Plot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch yes but how to create them ? We need each batch size to be smaller than the model's limit. We implemented a function that combine the prompt and the formatted plot, and add them until it reach the limit. The function return the ID of the first plot of each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the test set (no batch needed)\n",
    "Classifier.batch_plots(TestSet)\n",
    "\n",
    "#for the dataset !\n",
    "#clean_batch = Classifier.batch_plots(CleanData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "####  2.2.6 Assess the model on the training set\n",
    "Here we go ! Now we will call the model on the test set and compare the result with the human labelled data. Note that we don't have to train the data, but we still split the test data between train and validation. This is because we went to have a set of labelled data to compare the result with during the prompt fine-tuning and all the test of the model. We still want to have a dataset the model have never seen to test at the end with the final model. If the result is good enough, we will label all the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a firewall boolean to avoid running the model by accident\n",
    "Run_test = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the format of the final call of the model\n",
    "\n",
    "```ruby\n",
    "    completion = self.client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": self.Content},\n",
    "            {\"role\": \"user\",\"content\": Text},\n",
    "            {\"role\": \"assistant\", \"content\": self.Example}\n",
    "        ],\n",
    "        functions=[self.function],\n",
    "        function_call={\"name\": \"Assign_violence_level\"},\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.format_batch(TrainingSet[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also make smaller batch to improve the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "BatchSize = 10\n",
    "\n",
    "if Run_test :\n",
    "    for i in range(0,int(TrainingSet.shape[0]/BatchSize)+1) :\n",
    "        thisBatch = Classifier.format_batch(TrainingSet[i*BatchSize:min((i+1)*BatchSize,TrainingSet.shape[0])])\n",
    "        pred = Classifier.Call_API(thisBatch)\n",
    "        #print(\"pred\",len(pred))\n",
    "        prediction = prediction + pred\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare = pd.DataFrame(prediction,index=TrainingSet.index, columns=[\"Result\"])\n",
    "\n",
    "def to_level(data) :\n",
    "    match data:\n",
    "        case 'Peaceful':\n",
    "            return -1.0\n",
    "        case 'Mild':\n",
    "            return 0.0\n",
    "        case 'Violent':\n",
    "            return 1.0\n",
    "        case _:\n",
    "            raise Exception(\"wait is that ?\",data)\n",
    "\n",
    "Compare[\"Prediction\"] = Compare[\"Result\"].apply(to_level)\n",
    "\n",
    "Compare[\"Label\"] = TrainingSet[\"Answer\"]\n",
    "Compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"model_1\"\n",
    "Compare.to_csv(clean+\"/classification_result/\"+name+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(Compare[\"Label\"],Compare[\"Prediction\"])\n",
    "print(\"accuracy\",accuracy*100)\n",
    "\n",
    "m1 = abs(Compare[\"Label\"]-Compare[\"Prediction\"]).mean()\n",
    "print(\"abs distance\",m1)\n",
    "\n",
    "#penalize more if opposite result \n",
    "m2 = np.power(Compare[\"Label\"]-Compare[\"Prediction\"], 2).mean()\n",
    "print(\"pow distance\",m2)\n",
    "\n",
    "print(\"Correct label\",(Compare[\"Label\"]==Compare[\"Prediction\"]).sum())\n",
    "print(\"incorrect but close\",(abs(Compare[\"Label\"]-Compare[\"Prediction\"])==1).sum())\n",
    "print(\"opposite\",(abs(Compare[\"Label\"]-Compare[\"Prediction\"])==2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare[(abs(Compare[\"Label\"]-Compare[\"Prediction\"])==1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare[(abs(Compare[\"Label\"]-Compare[\"Prediction\"])==2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Testing history :</b>\n",
    "- <ins>first model</ins> 0.5% accuracy. It is not totally wrong but is usually close but not perfect. This could also be due to error during labelling. As we discussed, the notion of violence is complex. We should take this into account while labelling. We will try to improve the model accuracy by giving him typical *example*. Another problem is that with too much movie, the model forget some labels. we will return a *dictionary* instead of a list to associate the plot number to the returning class and ultimately reduce the *batch size*.\n",
    "- <ins>Add example to the prompt</ins> the result get a little better. however still a lot of incorrect but close response. Tend to consider more violent than expected. Adapt the class label.\n",
    "- <ins>Clearer definitions and smaller batch</ins> accuracy arroud 65%, likely to overestimate violence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.2.7 Apply to the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to be continued...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we :\n",
    "- Have chosen and cleaned our datasets.\n",
    "- Did preliminary analysis of the data, both on the movie and historical side.\n",
    "- Tested ways to classify movies into violent versus non-violent.\n",
    "\n",
    "in the future, we will\n",
    "- fine-tune our classifier and apply it to the whole dataset.\n",
    "- use regression analysis to assess the effect of each of the feature on the prediction.\n",
    "- look for correlation between our historical data and the violence in movies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
